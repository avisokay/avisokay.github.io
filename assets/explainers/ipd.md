---
layout: default
title: Inference on Predicted Data
---

# Inference on Predicted Data (IPD)

The problem: a researcher is interested in studying an outcome, Y, which is difficult to measure due to practical constraints such as time or cost. But they do have access to relatively cheap predictions of Y. They hypothesize that Y is associated with X, a set of features which are easier to measure. Their goal is to estimate a parameter of scientific interest, Œ∏, which describes the relationship between X and Y. How can the researcher attain valid estimates of Œ∏ relying upon mostly predicted outcomes of Y?

Regression we want is **Expensive** but **Precise** ‚Üí **Y = Œ∏‚ÇÅ X**  
Regression we have is **Cheaper** but **Noisier** ‚Üí **≈∂ = Œ∏‚ÇÇ X**  
Importantly, **Œ∏‚ÇÅ** is not the same as **Œ∏‚ÇÇ**!

Rhinoceros analogy from [Hoffman et al. 2024](https://arxiv.org/abs/2401.08702).

![Durer Rhino](/assets/img/durer_rhino.png)
![Koseman Rhino](/assets/img/koseman_rhino.png)

## What is "predicted data"?

In machine learning, "predicted data" are often thought of as the outputs from a complicated algorithm. I opt for an even broader definition: **any measure of a conceptual variable where a better, more direct measure exists.** This definition includes predictions from black-box AI models like chatGPT, but also includes other data we rely upon as social scientists, like survey responses, interviews, imputations, statistical estimates, derived measures, and a whole host of other proxies. Below is a table with some examples I have come across in my own research.

Every conceptual variable comes with different measurement challenges, but in general, more precise measurements are also more expensive to collect. A stylized image below shows that **expensive and precise** ground truth measures tend to live in the light blue region, with predicted data everywhere else. Because of this cost-quality tradeoff, we often resort to working with predicted data in practice. But not all predicted data are created equally! The best are those depicted in the green region - relatively **precise and cheap** compared to the red region - **noisy and expensive**.

## Measurements vary in both cost and precision

| Variable | Ground Truth | Predicted |
|----------|-------------|-----------|
| Cause of Death | Vital Registration | Verbal Autopsy |
| Obesity | Fat Percentage | BMI |
| Income | Admin Data | Self Reported |
| Environmental Attitude | Questionnaire | NLP Sentiment |

![Predictions Vary](../img/predictions_vary.png)

## What does it mean for inference on predicted data to be *invalid*?

In this context, valid statistical inference refers to both **un-biased point estimates** and **precise uncertainty bounds**. Relative to inference performed with "ground truth" outcomes, inference on predicted data may have biased point estimates due to systematic differences between predictions and the ground truth, and the reported uncertainty will be deceivingly narrow because it doesn't account for any of the prediction error.

Why does this matter? Consider a very simple hypothesis test where the p-value tells us whether or not an observed relationship between X and y is statistically significant. This conclusion is a function of both the point estimate and the uncertainty around that point estimate. The stylized diagram below demonstrates how bias and conservative uncertainty might lead to very different scientific conclusions.

## Inference can have bias and/or misleading uncertainty

![Valid Inference](../img/valid_inference.png)

## So how *do* you perform valid inference on predicted data?

There are several existing methods for performing the bias correction for valid inference with predicted data. While the technical details differ, these methods are built upon the same intuition. At its simplest, you incorporate what you learn when you have access to both ground truth and predicted outcomes into downstream inference where you rely solely on predicted outcomes. The two step procedure looks like this:

1. Using side-by-side ground truth and predicted measures of the outcome variable, estimate the **IPD rectifier, Œî**. This tells you how differences between Y and ≈∂ are associated with covariates X for the same observation.
   
   (Y·µ¢ - ≈∂·µ¢) = ŒîX·µ¢

2. Now, when you perform inference with predicted outcomes in the absence of ground truth measured outcomes, you incorporate the rectifier Œî into the naive parameters you estimate to recover valid IPD estimates.
   
   Invalid IPD ‚Üí ≈∂‚ÇÇ = Œ∏X‚ÇÇ  
   Correct IPD ‚Üí ≈∂‚ÇÇ = (Œ∏+Œî)X‚ÇÇ

## Cartoon example: height and basketball ability

We are interested in the association between a person's height and an index of their basketball ability on a scale from 1-10. Height can be measured directly, or from a self-report. Some people might report correctly, others might not, so we consider the self-reported height **predicted** data relative to directly measured height as **ground truth** data.

![Height](../img/height.png)

Oops! It looks like some people report being a couple inches taller than they actually are... How does this affect our conclusion about the association between height and basketball ability when we are relying on mostly self-reported height outcomes? Let's see. This is what it looks like to learn the **rectifier Œî** from the labeled data to correct inference performed on the unlabeled data.

![Bball Data](../img/bball_data.png)

First, we have some labeled data, *‚Ñì*, with observed basketball ability üèÄ, with both measured height üìè and self-reported height ‚úèÔ∏è. We also have some unlabeled data, *Œº‚Ñì*, with observed basketball ability üèÄ and only self-reported height ‚úèÔ∏è.

For the labeled data *‚Ñì*, we can specify the relationship, Œ≤, between height {measured:üìè:y‚Çò} or {reported:‚úèÔ∏è:y·µ£} and basketball ability {üèÄ:X‚Çó} with the following equations:

yüìè = Œ≤üìè üèÄ‚Çó or y‚Çò = Œ≤‚ÇòX‚Çó  
y‚úèÔ∏è = Œ≤‚úèÔ∏èüèÄ‚Çó or y·µ£ = Œ≤·µ£X‚Çó

solution for Œ≤‚Çò written as Œ≤‚Çò = (X‚Çó·µÄX‚Çó)‚Åª¬πX‚Çó·µÄy‚Çò  
solution for Œ≤·µ£ written as Œ≤·µ£ = (X‚Çó·µÄX‚Çó)‚Åª¬πX‚Çó·µÄy·µ£

and residuals of reported height y‚úèÔ∏è and measured height yüìè

![Height Residuals](../img/height_residuals.png)

![IPD Rectifier](../img/ipd_rectifier.png)

After matrix multiplication, rectifier Œî works out to **-1.375**. To recover the IPD corrected estimate Œ≤·µ¢‚Çö·¥Ö from the unlabeled data *Œº‚Ñì*, we first estimate Œ≤·µ£ from y·µ£ = Œ≤·µ£XŒº‚Ñì just like above. We find that *Œº‚Ñì* Œ≤·µ£ is **1.41**. Then, we subtract the rectifier Œî from Œ≤·µ£ to find Œ≤·µ¢‚Çö·¥Ö. This gives

Œ≤·µ¢‚Çö·¥Ö = Œ≤·µ£ - Œî  
1.41 - (-1.375) = 2.78  
**Œ≤·µ¢‚Çö·¥Ö = 2.78**

Below, you can see how the estimated relationships (*‚Ñì* Œ≤·µ£, *‚Ñì* Œ≤‚Çò, *Œº‚Ñì* Œ≤·µ£, *Œº‚Ñì* Œ≤·µ¢‚Çö·¥Ö) compare to eachother. In the labeled data *‚Ñì*, we see that the ground truth relationship between basketball ability and directly measured height is Œ≤‚Çò=2.37. Because some people self-reported being taller than they actually are, the estimated relationship is much weaker, with Œ≤·µ£=1. Moving to the unlabeled data *Œº‚Ñì*, we see that the naive estimate of the relationship between self-reported height and basketball ability is similarly weak, with Œ≤·µ£ = 1.41.

![IPD Plot](../img/ipd_plot.png)

Leveraging the relationship between directly measured height üìè and self-reported height ‚úèÔ∏è in the labeled dataset *‚Ñì* enables us to produce a valid estimate Œ≤·µ¢‚Çö·¥Ö in the unlabeled dataset *Œº‚Ñì*. Œ≤·µ¢‚Çö·¥Ö = 2.78 is much closer to the ground truth Œ≤‚Çò=2.37, and we arrive at this conclusion even in the absense of ground truth measures in the unlabeled dataset *Œº‚Ñì*. The magnitude of the ground truth relationship between height and basketball ability is much larger than we would conclude from inference on predicted data. For more discussion about how IPD correction can alter your scientific conclusions, check out [Section 4.3](https://openreview.net/forum?id=QbCHlIqbDJ#discussion) from my 2024 paper *From Narratives to Numbers: Valid Inference Using Language Model Predictions from Verbal Autopsies*.

## How to determine if IPD correction makes sense for your problem:

![Flowchart](../img/flowchart.png)

## IPD References
(in reverse order of publication date)

1. Methods for correcting inference based on outcomes predicted by machine learning. **(PostPI)**  
   *Wang, McCormick and Leek.* 2020 [PNAS](https://www.pnas.org/doi/suppl/10.1073/pnas.2001238117).

2. Prediction-powered inference. **(PPI)**  
   *Angelopoulos, Bates, Fannjiang, Jordan and Zrnic.* 2023a [Science](https://www.science.org/doi/10.1126/science.adi6000).

3. PPI++: Efficient Prediction-Powered Inference. **(PPI++)**  
   *Angelopoulos, Duchi and Zrnic.* 2023b [arxiv](https://arxiv.org/abs/2311.01453).

4. Assumption-Lean and Data-Adaptive Post-Prediction Inference. **(PSPA)**  
   *Miao, Miao, Wu, Zhao and Lu.* 2023 [arxiv](https://arxiv.org/abs/2311.14220).

5. Do We Really Even Need Data? ü¶è  
   *Hoffman, Salerno, Afiaz, Leek and McCormick.* 2024 [arxiv](https://arxiv.org/abs/2401.08702).

6. From Narratives to Numbers: Valid Inference Using Language Model Predictions from Verbal Autopsies **(multiPPI++)**  
   *Fan, Visokay, Hoffman, Salerno, Liu, Leek and McCormick.* 2024 [COLM](https://openreview.net/forum?id=QbCHlIqbDJ#discussion).

7. Code respository for the `ipd` package can be found [here](https://github.com/ipd-tools/ipd).